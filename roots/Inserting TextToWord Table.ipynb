{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9890739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent libraries \n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import Error\n",
    "import pandas.io.sql as sqlio\n",
    "\n",
    "# Read in the data file that we need to insert\n",
    "df = pd.read_excel(\"/Users/tahir/Desktop/Github/documents/roots/Data/Cleaned_Root_letters.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340fca67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799 records inserted successfully into rootWords table\n",
      "17623 records inserted successfully into ArabicWord table\n",
      "77791 records inserted successfully into TextToWord table\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Import relevent libraries \n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Read in the data file that we need to insert\n",
    "df = pd.read_excel(\"/Users/tahir/Desktop/Github/documents/roots/Data/Cleaned_Root_letters.xlsx\")\n",
    "\n",
    "# Prep Data for RootWords Table \n",
    "lst = list(df['Root_Letters'])\n",
    "lst = set(lst)\n",
    "\n",
    "# Make it into a dataframe, and give it an index / ID column \n",
    "df_roots = pd.DataFrame(lst, columns=['Root_Words'])\n",
    "df_roots = df_roots.reset_index()\n",
    "\n",
    "# df_roots[\"Root_Words\"] = lst\n",
    "df_roots[\"Root_Words\"] = df_roots[\"Root_Words\"].values.astype(str)\n",
    "\n",
    "# Put the data in the format the db accepts\n",
    "root_data = []\n",
    "for row in df_roots.index:\n",
    "    arabic_text = df_roots.loc[row,\"Root_Words\"]\n",
    "    unique_id = row\n",
    "    root_data.append((row, arabic_text))\n",
    "\n",
    "# Prep Data for the ArabicWord Table\n",
    "arabic_df = df.drop(['ID', 'Transliteration'], axis=1)\n",
    "arabic_df = arabic_df.drop_duplicates()\n",
    "arabic_df[\"primary_key\"] = list(range(2000,19623)) \n",
    "\n",
    "# Merge the df to get the RootWords PK (called \"index\")\n",
    "arabic_words_df = arabic_df.merge(df_roots, how='inner', left_on='Root_Letters', right_on='Root_Words')\n",
    "arabic_words_df = arabic_words_df.drop(['Root_Letters', 'Root_Words'], axis=1)\n",
    "\n",
    "# Rename the index column to RootID to make it clear\n",
    "arabic_words_df.rename(columns = {'index':'RootID'}, inplace = True)\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "arabic_words_data = []\n",
    "for index, row in arabic_words_df.iterrows():\n",
    "    arabic_words_data.append( (row['primary_key'], row['ARABIC'], row['RootID']) )\n",
    "    \n",
    "\n",
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "    \n",
    "########################################\n",
    "### GET data for  TEXT TO WORD table ###\n",
    "########################################\n",
    "\n",
    "# Create surah and ayah columns \n",
    "surah, ayah = [], []\n",
    "for row in df[\"ID\"]:\n",
    "    surah.append( row.split(\":\")[0] ) \n",
    "    ayah.append( row.split(\":\")[1] ) \n",
    "df[\"Surah\"] = surah\n",
    "df[\"Ayah\"] = ayah\n",
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)\n",
    "\n",
    "# Generate our text to words table\n",
    "TextToWords_df = df.merge(arabic_words_df, left_on =\"ARABIC\", right_on = \"ARABIC\", how = 'inner')\n",
    "TextToWords_df = TextToWords_df.reset_index()\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "TexttoWord = []\n",
    "for index, row in TextToWords_df.iterrows():\n",
    "    TexttoWord.append( (row['index'], row['Ayah'], row['primary_key']))\n",
    "    \n",
    "\n",
    "# Create functions to insert root words, arabic words and text to word data   \n",
    "def insert_root_words(root_words_data):\n",
    "    \"\"\" Insert Root Words Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO RootWords (RootID, RootWord) VALUES (%s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in root_words_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into rootWords table\")\n",
    "    return counter\n",
    "\n",
    "def insert_arabic_text(arabic_text_data):\n",
    "    \"\"\" Insert Arabic Text Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO ArabicWord (WordID, Word, RootID) VALUES (%s ,%s, %s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in arabic_text_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into ArabicWord table\")\n",
    "    return counter\n",
    "\n",
    "# Create function to get the quran text data \n",
    "def get_quran_text_df():\n",
    "    \"\"\" Get the quran text dataframe \"\"\"\n",
    "    postgreSQL_select_Query = \"select * from quran_text\"\n",
    "    cursor.execute(postgreSQL_select_Query)\n",
    "    print(\"Selecting rows from table using cursor.fetchall\")\n",
    "    sql_table_result = cursor.fetchall()\n",
    "    quran_text_df = pd.DataFrame(sql_table_result, columns=['index', 'sura', 'aya','text'])\n",
    "    return quran_text_df\n",
    "\n",
    "def insert_text_to_word(text_to_word_data):\n",
    "    \"\"\" Insert Text to Word  Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO TextToWord (IndexID, AyahID, WordID) VALUES (%s, %s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in text_to_word_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into TextToWord table\")\n",
    "    return counter\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Insert the root_words data \n",
    "    insert_root_words(root_data)\n",
    "\n",
    "    # Insert the arabic words data \n",
    "    insert_arabic_text(arabic_words_data)\n",
    "    \n",
    "    # Get the quran text df\n",
    "    quran_text = get_quran_text_df\n",
    "    \n",
    "    # Insert text_to_word_df\n",
    "    insert_text_to_word(TexttoWord)\n",
    "\n",
    "    # Close the DB connection \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75feff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d33e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "       WHERE table_schema = 'public'\"\"\")\n",
    "for table in cursor.fetchall():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfecfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "postgreSQL_select_Query = \"select * from quran_text\"\n",
    "cursor.execute(postgreSQL_select_Query)\n",
    "print(\"Selecting rows from table using cursor.fetchall\")\n",
    "sql_table_result = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19def049",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text = pd.DataFrame(sql_table_result, columns=['index', 'sura', 'aya','text'])\n",
    "quran_text.head()\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ebeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the DB connection \n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9905b4c",
   "metadata": {},
   "source": [
    "# List out all tables we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fea51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another column for surah and ayat, extracted from ID\n",
    "surah, ayah = [], []\n",
    "for row in df[\"ID\"]:\n",
    "    surah.append( row.split(\":\")[0] ) \n",
    "    ayah.append( row.split(\":\")[1] ) \n",
    "\n",
    "df[\"Surah\"] = surah\n",
    "df[\"Ayah\"] = ayah\n",
    "\n",
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f70ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc9c2c0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARABIC</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>RootID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بِسْمِ</td>\n",
       "      <td>2000</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>السَّمَاءِ</td>\n",
       "      <td>2158</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَالسَّمَاءَ</td>\n",
       "      <td>2199</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سَمَاوَاتٍ</td>\n",
       "      <td>2302</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الْأَسْمَاءَ</td>\n",
       "      <td>2325</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17618</th>\n",
       "      <td>مَسَدٍ</td>\n",
       "      <td>19606</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17619</th>\n",
       "      <td>الصَّمَدُ</td>\n",
       "      <td>19607</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17620</th>\n",
       "      <td>كُفُوًا</td>\n",
       "      <td>19610</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>وَقَبَ</td>\n",
       "      <td>19614</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17622</th>\n",
       "      <td>النَّفَّاثَاتِ</td>\n",
       "      <td>19615</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17623 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARABIC  primary_key  RootID\n",
       "0              بِسْمِ         2000    1641\n",
       "1          السَّمَاءِ         2158    1641\n",
       "2        وَالسَّمَاءَ         2199    1641\n",
       "3          سَمَاوَاتٍ         2302    1641\n",
       "4        الْأَسْمَاءَ         2325    1641\n",
       "...               ...          ...     ...\n",
       "17618          مَسَدٍ        19606     268\n",
       "17619       الصَّمَدُ        19607    1086\n",
       "17620         كُفُوًا        19610    1359\n",
       "17621          وَقَبَ        19614     936\n",
       "17622  النَّفَّاثَاتِ        19615    1557\n",
       "\n",
       "[17623 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010d4d3",
   "metadata": {},
   "source": [
    "# Create the TexttoWord table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = quran_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd06ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextToWords_df = df.merge(arabic_words_df, left_on =\"ARABIC\", right_on = \"ARABIC\", how = 'inner')\n",
    "TextToWords_df = TextToWords_df.reset_index()\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "TexttoWord = []\n",
    "for index, row in TextToWords_df.iterrows():\n",
    "    TexttoWord.append( (row['index'], row['Ayah'], row['primary_key']))\n",
    "    \n",
    "def insert_text_to_word(text_to_word_data):\n",
    "    \"\"\" Insert Text to Word  Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO TextToWord (IndexID, AyahID, WordID) VALUES (%s, %s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in text_to_word_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into TextToWord table\")\n",
    "    return counter\n",
    "\n",
    "insert_text_to_word(TexttoWord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de53fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp2.reset_index()\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d407367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the dataframe into the format for postgres sql insertion \n",
    "TexttoWord = []\n",
    "for index, row in temp2.iterrows():\n",
    "    TexttoWord.append( (row['index'], row['Ayah'], row['primary_key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558096a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_text_to_word(text_to_word_data):\n",
    "    \"\"\" Insert Text to Word  Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO TextToWord (IndexID, AyahID, WordID) VALUES (%s, %s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in text_to_word_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into TextToWord table\")\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc952cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_text_to_word(TexttoWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d48de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee764a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da71780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71faa6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7ce8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "postgreSQL_select_Query = \"select * from quran_text\"\n",
    "cursor.execute(postgreSQL_select_Query)\n",
    "print(\"Selecting rows from quran table using cursor.fetchall\")\n",
    "quran_text_full = cursor.fetchall()\n",
    "\n",
    "print(\"Print each row and it's columns values\")\n",
    "index, surah, ayah, text = [], [], [], [] \n",
    "for row in quran_text_full:\n",
    "    index.append(row[0])\n",
    "    surah.append(row[1])\n",
    "    ayah.append(row[2])\n",
    "    text.append(row[3])\n",
    "    \n",
    "quran_text_df = pd.DataFrame(\n",
    "    {'Index': index,\n",
    "     'Surah': surah,\n",
    "     'Ayah': ayah,\n",
    "     'Text': text\n",
    "    })\n",
    "quran_text_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgreSQL_select_Query = \"select * from ArabicWord\"\n",
    "cursor.execute(postgreSQL_select_Query)\n",
    "print(\"Selecting rows from quran table using cursor.fetchall\")\n",
    "quran_text_full = cursor.fetchall()\n",
    "print(quran_text_full[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa809ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the DB connection \n",
    "cursor.close()\n",
    "connection.close()\n",
    "print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb6f1f",
   "metadata": {},
   "source": [
    "# Now that we have the data... its time to prep it for our db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a54fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextToWord = df.merge(quran_text_full, on = [\"Word\", \"Ayah\" ], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc5076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quran_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd807c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e50b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3  = quran_text_df.merge(df, on = [\"Surah\", \"Ayah\" ], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52294bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85929998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.merge(arabic_words_df, on = \"ARABIC\", how = 'inner')\n",
    "df4fa885769a2d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9e229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17084e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.drop_duplicates()\n",
    "df5.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60976444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[\"index2\"] = df5[\"Index\"]\n",
    "df5 = df5.drop([\"Index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40291a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prep data\n",
    "# Put the data in the format the db accepts\n",
    "text_to_word_data = []\n",
    "for row in df5.index:\n",
    "    AyahID = text_to_word_data.loc[row,\"index2\"]\n",
    "    WordID = text_to_word_data.loc[row,\"primary_key\"]\n",
    "    \n",
    "    text_to_word_data.append((AyahID, WordID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.merge(arabic_words_df, left_on =\"ARABIC\", right_on = \"ARABIC\", how = 'outer')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77121be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_words_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53667d30",
   "metadata": {},
   "source": [
    "## WHat we want: \n",
    "\n",
    "DROP TABLE IF EXISTS TextToWord;\n",
    "CREATE TABLE IF NOT EXISTS TextToWord  (\n",
    "    AyahID INT NOT NULL,\n",
    "    WordID INT NOT NULL,\n",
    "    PRIMARY KEY (AyahID, WordID),\n",
    "    FOREIGN KEY (AyahID)\n",
    "        REFERENCES quran_text(\"index\")\n",
    "        ON DELETE CASCADE\n",
    "        ON UPDATE CASCADE,\n",
    "\tFOREIGN KEY (WordID)\n",
    "\t\tREFERENCES ArabicWord(WordID)\n",
    "\t\tON DELETE CASCADE\n",
    "\t\tON UPDATE CASCADE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AyahID = quran_text_df[\"Index\"]\n",
    "WordID = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb7380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a68bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b442b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1906cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b25e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Data for RootWords Table \n",
    "lst = list(df['Root_Letters'])\n",
    "lst = set(lst)\n",
    "\n",
    "# Make it into a dataframe, and give it an index / ID column \n",
    "df_roots = pd.DataFrame(lst, columns=['Root_Words'])\n",
    "df_roots = df_roots.reset_index()\n",
    "\n",
    "# df_roots[\"Root_Words\"] = lst\n",
    "df_roots[\"Root_Words\"] = df_roots[\"Root_Words\"].values.astype(str)\n",
    "\n",
    "# Put the data in the format the db accepts\n",
    "root_data = []\n",
    "for row in df_roots.index:\n",
    "    arabic_text = df_roots.loc[row,\"Root_Words\"]\n",
    "    unique_id = row\n",
    "    root_data.append((row, arabic_text))\n",
    "\n",
    "# Prep Data for the ArabicWord Table\n",
    "arabic_df = df.drop(['ID', 'Transliteration'], axis=1)\n",
    "# arabic_df = arabic_df.drop_duplicates()\n",
    "arabic_df[\"primary_key\"] = list(range(2000,19623)) \n",
    "\n",
    "# Merge the df to get the RootWords PK (called \"index\")\n",
    "arabic_words_df = arabic_df.merge(df_roots, how='inner', left_on='Root_Letters', right_on='Root_Words')\n",
    "arabic_words_df = arabic_words_df.drop(['Root_Letters', 'Root_Words'], axis=1)\n",
    "\n",
    "# Rename the index column to RootID to make it clear\n",
    "arabic_words_df.rename(columns = {'index':'RootID'}, inplace = True)\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "arabic_words_data = []\n",
    "for index, row in arabic_words_df.iterrows():\n",
    "    arabic_words_data.append( (row['primary_key'], row['ARABIC'], row['RootID']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5db91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08699c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d9cb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the DB connection \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent libraries \n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Read in the data file that we need to insert\n",
    "df = pd.read_excel(\"/Users/tahir/Desktop/Github/documents/roots/Data/Cleaned_Root_letters.xlsx\")\n",
    "\n",
    "# Prep Data for RootWords Table \n",
    "lst = list(df['Root_Letters'])\n",
    "lst = set(lst)\n",
    "\n",
    "# Make it into a dataframe, and give it an index / ID column \n",
    "df_roots = pd.DataFrame(lst, columns=['Root_Words'])\n",
    "df_roots = df_roots.reset_index()\n",
    "\n",
    "# df_roots[\"Root_Words\"] = lst\n",
    "df_roots[\"Root_Words\"] = df_roots[\"Root_Words\"].values.astype(str)\n",
    "\n",
    "# Put the data in the format the db accepts\n",
    "root_data = []\n",
    "for row in df_roots.index:\n",
    "    arabic_text = df_roots.loc[row,\"Root_Words\"]\n",
    "    unique_id = row\n",
    "    root_data.append((row, arabic_text))\n",
    "\n",
    "# Prep Data for the ArabicWord Table\n",
    "arabic_df = df.drop(['ID', 'Transliteration'], axis=1)\n",
    "arabic_df = arabic_df.drop_duplicates()\n",
    "arabic_df[\"primary_key\"] = list(range(2000,19623)) \n",
    "\n",
    "# Merge the df to get the RootWords PK (called \"index\")\n",
    "arabic_words_df = arabic_df.merge(df_roots, how='inner', left_on='Root_Letters', right_on='Root_Words')\n",
    "arabic_words_df = arabic_words_df.drop(['Root_Letters', 'Root_Words'], axis=1)\n",
    "\n",
    "# Rename the index column to RootID to make it clear\n",
    "arabic_words_df.rename(columns = {'index':'RootID'}, inplace = True)\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "arabic_words_data = []\n",
    "for index, row in arabic_words_df.iterrows():\n",
    "    arabic_words_data.append( (row['primary_key'], row['ARABIC'], row['RootID']) )\n",
    "\n",
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "    \n",
    "# Create functions to insert root words and arabic words data     \n",
    "def insert_root_words(root_words_data):\n",
    "    \"\"\" Insert Root Words Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO RootWords (RootID, RootWord) VALUES (%s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in root_words_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into rootWords table\")\n",
    "    return counter\n",
    "\n",
    "def insert_arabic_text(arabic_text_data):\n",
    "    \"\"\" Insert Arabic Text Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO ArabicWord (WordID, Word, RootID) VALUES (%s ,%s, %s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in arabic_text_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into ArabicWord table\")\n",
    "    return counter\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Insert the root_words data \n",
    "    #insert_root_words(root_data)\n",
    "\n",
    "    # Insert the arabic words data \n",
    "    #insert_arabic_text(arabic_words_data)\n",
    "\n",
    "    # Close the DB connection \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2982865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
