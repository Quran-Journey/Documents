{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9890739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent libraries \n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import Error\n",
    "import pandas.io.sql as sqlio\n",
    "\n",
    "# Read in the data file that we need to insert\n",
    "df = pd.read_excel(\"/Users/tahir/Desktop/Github/documents/db/Data/Cleaned_Root_letters.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310d362",
   "metadata": {},
   "source": [
    "## THE CELL BELOW SHOULD CREATE 3 TABLES AND INSERT DATA IN THEM ## \n",
    "\n",
    "\n",
    "(SAME as the .py script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340fca67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799 records inserted successfully into rootWords table\n",
      "17623 records inserted successfully into ArabicWord table\n",
      "58222 records inserted successfully into TextToWord table\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Import relevent libraries \n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Read in the data file that we need to insert\n",
    "df = pd.read_excel(\"/Users/tahir/Desktop/Github/documents/db/Data/Cleaned_Root_letters.xlsx\")\n",
    "\n",
    "# Prep Data for RootWords Table \n",
    "lst = list(df['Root_Letters'])\n",
    "lst = set(lst)\n",
    "\n",
    "# Make it into a dataframe, and give it an index / ID column \n",
    "df_roots = pd.DataFrame(lst, columns=['Root_Words'])\n",
    "df_roots = df_roots.reset_index()\n",
    "\n",
    "# df_roots[\"Root_Words\"] = lst\n",
    "df_roots[\"Root_Words\"] = df_roots[\"Root_Words\"].values.astype(str)\n",
    "\n",
    "# Put the data in the format the db accepts\n",
    "root_data = []\n",
    "for row in df_roots.index:\n",
    "    arabic_text = df_roots.loc[row,\"Root_Words\"]\n",
    "    unique_id = row\n",
    "    root_data.append((row, arabic_text))\n",
    "\n",
    "# Prep Data for the ArabicWord Table\n",
    "arabic_df = df.drop(['ID', 'Transliteration'], axis=1)\n",
    "arabic_df = arabic_df.drop_duplicates()\n",
    "arabic_df[\"primary_key\"] = list(range(2000,19623)) \n",
    "\n",
    "# Merge the df to get the RootWords PK (called \"index\")\n",
    "arabic_words_df = arabic_df.merge(df_roots, how='inner', left_on='Root_Letters', right_on='Root_Words')\n",
    "arabic_words_df = arabic_words_df.drop(['Root_Letters', 'Root_Words'], axis=1)\n",
    "\n",
    "# Rename the index column to RootID to make it clear\n",
    "arabic_words_df.rename(columns = {'index':'RootID'}, inplace = True)\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "arabic_words_data = []\n",
    "for index, row in arabic_words_df.iterrows():\n",
    "    arabic_words_data.append( (row['primary_key'], row['ARABIC'], row['RootID']) )\n",
    "    \n",
    "\n",
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "    \n",
    "########################################\n",
    "### GET data for  TEXT TO WORD table ###\n",
    "########################################\n",
    "\n",
    "# Create surah and ayah columns \n",
    "surah, ayah = [], []\n",
    "for row in df[\"ID\"]:\n",
    "    surah.append( row.split(\":\")[0] ) \n",
    "    ayah.append( row.split(\":\")[1] ) \n",
    "df[\"Surah\"] = surah\n",
    "df[\"Ayah\"] = ayah\n",
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)\n",
    "\n",
    "# Generate our text to words table\n",
    "TextToWords_df = df.merge(arabic_words_df, left_on =\"ARABIC\", right_on = \"ARABIC\", how = 'inner')\n",
    "TextToWords_df = TextToWords_df.reset_index()\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "TexttoWord = []\n",
    "for index, row in TextToWords_df.iterrows():\n",
    "    tup = tuple((row['Ayah'], row['primary_key']))\n",
    "    if tup not in TexttoWord:\n",
    "        TexttoWord.append( tup )\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Create functions to insert root words, arabic words and text to word data   \n",
    "def insert_root_words(root_words_data):\n",
    "    \"\"\" Insert Root Words Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO RootWords (RootID, RootWord) VALUES (%s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in root_words_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into rootWords table\")\n",
    "    return counter\n",
    "\n",
    "def insert_arabic_text(arabic_text_data):\n",
    "    \"\"\" Insert Arabic Text Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO ArabicWord (WordID, Word, RootID) VALUES (%s ,%s, %s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in arabic_text_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into ArabicWord table\")\n",
    "    return counter\n",
    "\n",
    "# Create function to get the quran text data \n",
    "def get_quran_text_df():\n",
    "    \"\"\" Get the quran text dataframe \"\"\"\n",
    "    postgreSQL_select_Query = \"select * from quran_text\"\n",
    "    cursor.execute(postgreSQL_select_Query)\n",
    "    print(\"Selecting rows from table using cursor.fetchall\")\n",
    "    sql_table_result = cursor.fetchall()\n",
    "    quran_text_df = pd.DataFrame(sql_table_result, columns=['index', 'sura', 'aya','text'])\n",
    "    return quran_text_df\n",
    "\n",
    "def insert_text_to_word(text_to_word_data):\n",
    "    \"\"\" Insert Text to Word  Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO TextToWord (AyahID, WordID) VALUES (%s, %s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in text_to_word_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into TextToWord table\")\n",
    "    return counter\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Insert the root_words data \n",
    "    insert_root_words(root_data)\n",
    "\n",
    "    # Insert the arabic words data \n",
    "    insert_arabic_text(arabic_words_data)\n",
    "    \n",
    "    # Get the quran text df\n",
    "    quran_text = get_quran_text_df\n",
    "    \n",
    "    # Insert text_to_word_df\n",
    "    insert_text_to_word(TexttoWord)\n",
    "\n",
    "    # Close the DB connection \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75feff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d33e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('quran_text',)\n",
      "('rootwords',)\n",
      "('arabicword',)\n",
      "('texttoword',)\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"SELECT table_name FROM information_schema.tables\n",
    "       WHERE table_schema = 'public'\"\"\")\n",
    "for table in cursor.fetchall():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48cfecfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting rows from table using cursor.fetchall\n"
     ]
    }
   ],
   "source": [
    "postgreSQL_select_Query = \"select * from texttoword\"\n",
    "cursor.execute(postgreSQL_select_Query)\n",
    "print(\"Selecting rows from table using cursor.fetchall\")\n",
    "sql_table_result = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19def049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2000),\n",
       " (41, 2000),\n",
       " (30, 2000),\n",
       " (1, 2001),\n",
       " (23, 2001),\n",
       " (27, 2001),\n",
       " (60, 2001),\n",
       " (61, 2001),\n",
       " (64, 2001),\n",
       " (74, 2001),\n",
       " (75, 2001),\n",
       " (79, 2001),\n",
       " (80, 2001),\n",
       " (89, 2001),\n",
       " (91, 2001),\n",
       " (94, 2001),\n",
       " (97, 2001),\n",
       " (101, 2001),\n",
       " (102, 2001),\n",
       " (103, 2001),\n",
       " (107, 2001),\n",
       " (110, 2001),\n",
       " (114, 2001),\n",
       " (115, 2001),\n",
       " (120, 2001),\n",
       " (138, 2001),\n",
       " (139, 2001),\n",
       " (140, 2001),\n",
       " (154, 2001),\n",
       " (158, 2001),\n",
       " (161, 2001),\n",
       " (165, 2001),\n",
       " (169, 2001),\n",
       " (173, 2001),\n",
       " (187, 2001),\n",
       " (190, 2001),\n",
       " (195, 2001),\n",
       " (207, 2001),\n",
       " (210, 2001),\n",
       " (211, 2001),\n",
       " (214, 2001),\n",
       " (217, 2001),\n",
       " (218, 2001),\n",
       " (229, 2001),\n",
       " (230, 2001),\n",
       " (231, 2001),\n",
       " (244, 2001),\n",
       " (246, 2001),\n",
       " (249, 2001),\n",
       " (251, 2001),\n",
       " (252, 2001),\n",
       " (261, 2001),\n",
       " (262, 2001),\n",
       " (265, 2001),\n",
       " (272, 2001),\n",
       " (273, 2001),\n",
       " (275, 2001),\n",
       " (279, 2001),\n",
       " (281, 2001),\n",
       " (282, 2001),\n",
       " (4, 2001),\n",
       " (10, 2001),\n",
       " (13, 2001),\n",
       " (15, 2001),\n",
       " (19, 2001),\n",
       " (21, 2001),\n",
       " (28, 2001),\n",
       " (37, 2001),\n",
       " (39, 2001),\n",
       " (49, 2001),\n",
       " (52, 2001),\n",
       " (59, 2001),\n",
       " (70, 2001),\n",
       " (73, 2001),\n",
       " (77, 2001),\n",
       " (78, 2001),\n",
       " (83, 2001),\n",
       " (87, 2001),\n",
       " (98, 2001),\n",
       " (99, 2001),\n",
       " (108, 2001),\n",
       " (109, 2001),\n",
       " (112, 2001),\n",
       " (113, 2001),\n",
       " (116, 2001),\n",
       " (122, 2001),\n",
       " (126, 2001),\n",
       " (145, 2001),\n",
       " (146, 2001),\n",
       " (157, 2001),\n",
       " (159, 2001),\n",
       " (160, 2001),\n",
       " (162, 2001),\n",
       " (163, 2001),\n",
       " (166, 2001),\n",
       " (167, 2001),\n",
       " (171, 2001),\n",
       " (174, 2001),\n",
       " (198, 2001),\n",
       " (199, 2001)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_table_result[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d091c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TexttoWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text = pd.DataFrame(sql_table_result, columns=['index', 'sura', 'aya','text'])\n",
    "quran_text.head()\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0bb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ebeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the DB connection \n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9905b4c",
   "metadata": {},
   "source": [
    "# List out all tables we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fea51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another column for surah and ayat, extracted from ID\n",
    "surah, ayah = [], []\n",
    "for row in df[\"ID\"]:\n",
    "    surah.append( row.split(\":\")[0] ) \n",
    "    ayah.append( row.split(\":\")[1] ) \n",
    "\n",
    "df[\"Surah\"] = surah\n",
    "df[\"Ayah\"] = ayah\n",
    "\n",
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f70ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c2c0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arabic_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010d4d3",
   "metadata": {},
   "source": [
    "# Create the TexttoWord table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = quran_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd06ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextToWords_df = df.merge(arabic_words_df, left_on =\"ARABIC\", right_on = \"ARABIC\", how = 'inner')\n",
    "TextToWords_df = TextToWords_df.reset_index()\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "TexttoWord = []\n",
    "for index, row in TextToWords_df.iterrows():\n",
    "    TexttoWord.append( (row['index'], row['Ayah'], row['primary_key']))\n",
    "    \n",
    "def insert_text_to_word(text_to_word_data):\n",
    "    \"\"\" Insert Text to Word  Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO TextToWord (IndexID, AyahID, WordID) VALUES (%s, %s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in text_to_word_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into TextToWord table\")\n",
    "    return counter\n",
    "\n",
    "insert_text_to_word(TexttoWord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8331158",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp2.reset_index()\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d407367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the dataframe into the format for postgres sql insertion \n",
    "TexttoWord = []\n",
    "for index, row in temp2.iterrows():\n",
    "    TexttoWord.append( (row['index'], row['Ayah'], row['primary_key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558096a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_text_to_word(text_to_word_data):\n",
    "    \"\"\" Insert Text to Word  Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO TextToWord (IndexID, AyahID, WordID) VALUES (%s, %s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in text_to_word_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into TextToWord table\")\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc952cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_text_to_word(TexttoWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d48de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee764a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da71780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71faa6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7ce8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "postgreSQL_select_Query = \"select * from quran_text\"\n",
    "cursor.execute(postgreSQL_select_Query)\n",
    "print(\"Selecting rows from quran table using cursor.fetchall\")\n",
    "quran_text_full = cursor.fetchall()\n",
    "\n",
    "print(\"Print each row and it's columns values\")\n",
    "index, surah, ayah, text = [], [], [], [] \n",
    "for row in quran_text_full:\n",
    "    index.append(row[0])\n",
    "    surah.append(row[1])\n",
    "    ayah.append(row[2])\n",
    "    text.append(row[3])\n",
    "    \n",
    "quran_text_df = pd.DataFrame(\n",
    "    {'Index': index,\n",
    "     'Surah': surah,\n",
    "     'Ayah': ayah,\n",
    "     'Text': text\n",
    "    })\n",
    "quran_text_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgreSQL_select_Query = \"select * from ArabicWord\"\n",
    "cursor.execute(postgreSQL_select_Query)\n",
    "print(\"Selecting rows from quran table using cursor.fetchall\")\n",
    "quran_text_full = cursor.fetchall()\n",
    "print(quran_text_full[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa809ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the DB connection \n",
    "cursor.close()\n",
    "connection.close()\n",
    "print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb6f1f",
   "metadata": {},
   "source": [
    "# Now that we have the data... its time to prep it for our db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a54fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextToWord = df.merge(quran_text_full, on = [\"Word\", \"Ayah\" ], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc5076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quran_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd807c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surah\"] = df[\"Surah\"].values.astype(int)\n",
    "df[\"Ayah\"] = df[\"Ayah\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e50b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28daf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3  = quran_text_df.merge(df, on = [\"Surah\", \"Ayah\" ], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52294bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85929998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.merge(arabic_words_df, on = \"ARABIC\", how = 'inner')\n",
    "df4fa885769a2d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9e229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17084e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.drop_duplicates()\n",
    "df5.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60976444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[\"index2\"] = df5[\"Index\"]\n",
    "df5 = df5.drop([\"Index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40291a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prep data\n",
    "# Put the data in the format the db accepts\n",
    "text_to_word_data = []\n",
    "for row in df5.index:\n",
    "    AyahID = text_to_word_data.loc[row,\"index2\"]\n",
    "    WordID = text_to_word_data.loc[row,\"primary_key\"]\n",
    "    \n",
    "    text_to_word_data.append((AyahID, WordID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.merge(arabic_words_df, left_on =\"ARABIC\", right_on = \"ARABIC\", how = 'outer')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77121be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_words_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53667d30",
   "metadata": {},
   "source": [
    "## WHat we want: \n",
    "\n",
    "DROP TABLE IF EXISTS TextToWord;\n",
    "CREATE TABLE IF NOT EXISTS TextToWord  (\n",
    "    AyahID INT NOT NULL,\n",
    "    WordID INT NOT NULL,\n",
    "    PRIMARY KEY (AyahID, WordID),\n",
    "    FOREIGN KEY (AyahID)\n",
    "        REFERENCES quran_text(\"index\")\n",
    "        ON DELETE CASCADE\n",
    "        ON UPDATE CASCADE,\n",
    "\tFOREIGN KEY (WordID)\n",
    "\t\tREFERENCES ArabicWord(WordID)\n",
    "\t\tON DELETE CASCADE\n",
    "\t\tON UPDATE CASCADE\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AyahID = quran_text_df[\"Index\"]\n",
    "WordID = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb7380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a68bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b442b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1906cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b25e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep Data for RootWords Table \n",
    "lst = list(df['Root_Letters'])\n",
    "lst = set(lst)\n",
    "\n",
    "# Make it into a dataframe, and give it an index / ID column \n",
    "df_roots = pd.DataFrame(lst, columns=['Root_Words'])\n",
    "df_roots = df_roots.reset_index()\n",
    "\n",
    "# df_roots[\"Root_Words\"] = lst\n",
    "df_roots[\"Root_Words\"] = df_roots[\"Root_Words\"].values.astype(str)\n",
    "\n",
    "# Put the data in the format the db accepts\n",
    "root_data = []\n",
    "for row in df_roots.index:\n",
    "    arabic_text = df_roots.loc[row,\"Root_Words\"]\n",
    "    unique_id = row\n",
    "    root_data.append((row, arabic_text))\n",
    "\n",
    "# Prep Data for the ArabicWord Table\n",
    "arabic_df = df.drop(['ID', 'Transliteration'], axis=1)\n",
    "# arabic_df = arabic_df.drop_duplicates()\n",
    "arabic_df[\"primary_key\"] = list(range(2000,19623)) \n",
    "\n",
    "# Merge the df to get the RootWords PK (called \"index\")\n",
    "arabic_words_df = arabic_df.merge(df_roots, how='inner', left_on='Root_Letters', right_on='Root_Words')\n",
    "arabic_words_df = arabic_words_df.drop(['Root_Letters', 'Root_Words'], axis=1)\n",
    "\n",
    "# Rename the index column to RootID to make it clear\n",
    "arabic_words_df.rename(columns = {'index':'RootID'}, inplace = True)\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "arabic_words_data = []\n",
    "for index, row in arabic_words_df.iterrows():\n",
    "    arabic_words_data.append( (row['primary_key'], row['ARABIC'], row['RootID']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5db91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08699c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d9cb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the DB connection \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent libraries \n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Read in the data file that we need to insert\n",
    "df = pd.read_excel(\"/Users/tahir/Desktop/Github/documents/roots/Data/Cleaned_Root_letters.xlsx\")\n",
    "\n",
    "# Prep Data for RootWords Table \n",
    "lst = list(df['Root_Letters'])\n",
    "lst = set(lst)\n",
    "\n",
    "# Make it into a dataframe, and give it an index / ID column \n",
    "df_roots = pd.DataFrame(lst, columns=['Root_Words'])\n",
    "df_roots = df_roots.reset_index()\n",
    "\n",
    "# df_roots[\"Root_Words\"] = lst\n",
    "df_roots[\"Root_Words\"] = df_roots[\"Root_Words\"].values.astype(str)\n",
    "\n",
    "# Put the data in the format the db accepts\n",
    "root_data = []\n",
    "for row in df_roots.index:\n",
    "    arabic_text = df_roots.loc[row,\"Root_Words\"]\n",
    "    unique_id = row\n",
    "    root_data.append((row, arabic_text))\n",
    "\n",
    "# Prep Data for the ArabicWord Table\n",
    "arabic_df = df.drop(['ID', 'Transliteration'], axis=1)\n",
    "arabic_df = arabic_df.drop_duplicates()\n",
    "arabic_df[\"primary_key\"] = list(range(2000,19623)) \n",
    "\n",
    "# Merge the df to get the RootWords PK (called \"index\")\n",
    "arabic_words_df = arabic_df.merge(df_roots, how='inner', left_on='Root_Letters', right_on='Root_Words')\n",
    "arabic_words_df = arabic_words_df.drop(['Root_Letters', 'Root_Words'], axis=1)\n",
    "\n",
    "# Rename the index column to RootID to make it clear\n",
    "arabic_words_df.rename(columns = {'index':'RootID'}, inplace = True)\n",
    "\n",
    "# Put the dataframe into the format for postgres sql insertion \n",
    "arabic_words_data = []\n",
    "for index, row in arabic_words_df.iterrows():\n",
    "    arabic_words_data.append( (row['primary_key'], row['ARABIC'], row['RootID']) )\n",
    "\n",
    "# Connect to the Postgres SQL Database \n",
    "try:         \n",
    "    # Define DB connection parameters \n",
    "    dbHost = '127.0.0.1'\n",
    "    dbPort = 5434\n",
    "    dbUser = 'qj'\n",
    "    dbPassword= 'Yatathakar123!'\n",
    "    dbName = 'quranJourney'\n",
    "\n",
    "    # connect to the PostgreSQL database\n",
    "    connection = psycopg2.connect(user=dbUser,\n",
    "                              password=dbPassword,\n",
    "                              host=dbHost,\n",
    "                              port=dbPort,\n",
    "                              database=dbName)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "    \n",
    "# Create functions to insert root words and arabic words data     \n",
    "def insert_root_words(root_words_data):\n",
    "    \"\"\" Insert Root Words Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO RootWords (RootID, RootWord) VALUES (%s ,%s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in root_words_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into rootWords table\")\n",
    "    return counter\n",
    "\n",
    "def insert_arabic_text(arabic_text_data):\n",
    "    \"\"\" Insert Arabic Text Data into the POSTGRES DB \"\"\"\n",
    "    postgres_insert_query = \"\"\" INSERT INTO ArabicWord (WordID, Word, RootID) VALUES (%s ,%s, %s)\"\"\"\n",
    "    counter = 0\n",
    "    for row in arabic_text_data:\n",
    "        record_to_insert = row\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "        counter += cursor.rowcount\n",
    "    print(counter, \"records inserted successfully into ArabicWord table\")\n",
    "    return counter\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Insert the root_words data \n",
    "    #insert_root_words(root_data)\n",
    "\n",
    "    # Insert the arabic words data \n",
    "    #insert_arabic_text(arabic_words_data)\n",
    "\n",
    "    # Close the DB connection \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2982865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
